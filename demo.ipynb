{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d9a172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\nikhi\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_10560\\466692661.py:36: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 100\n",
      "âœ… Chroma Vector DB created and persisted!\n",
      "\n",
      "--- Query: Tell me about honey bee farming course ---\n",
      "Answer:\n",
      "We have a **Course on Honey Bee Farming** available.\n",
      "\n",
      "This course is designed to help you transform your passion for bees into a lucrative career.\n",
      "\n",
      "It is suitable for:\n",
      "*   Beginners looking to start a career in beekeeping\n",
      "*   Experienced beekeepers looking to expand their knowledge and skills\n",
      "*   Entrepreneurs interested in starting their own beekeeping business\n",
      "*   Farmers and landowners looking to diversify their income\n",
      "*   Anyone with a passion for bees and a desire to learn about the industry\n",
      "\n",
      "The course is available in Hindi, Kannada, Malayalam, Tamil, Telugu, and English.\n",
      "\n",
      "Documents considered:\n",
      "Course Title: Course on Honey Bee Farming\n",
      "Description: Transform Your Passion for Bees into a Lucrative Career: Join Our Honey Bee Farming Course Now!\n",
      "Who This Course is For: Beginners looking to start a career in beekeeping ||| Experienced beekeepers looking to expand their knowledge and skills ||| Entrepreneurs interested in starting their own beekeeping business ||| Farmers and landowners looking to diversify their income ||| Anyone with a passion for bees and a desire to learn about the industry\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "Course Title: Course on Honey Bee Farming\n",
      "Description: Transform Your Passion for Bees into a Lucrative Career: Join Our Honey Bee Farming Course Now!\n",
      "Who This Course is For: Beginners looking to start a career in beekeeping ||| Experienced beekeepers looking to expand their knowledge and skills ||| Entrepreneurs interested in starting their own beekeeping business ||| Farmers and landowners looking to diversify their income ||| Anyone with a passion for bees and a desire to learn about the industry\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "Course Title: Course on Honey Bee Farming\n",
      "Description: Transform Your Passion for Bees into a Lucrative Career: Join Our Honey Bee Farming Course Now!\n",
      "Who This Course is For: Beginners looking to start a career in beekeeping ||| Experienced beekeepers looking to expand their knowledge and skills ||| Entrepreneurs interested in starting their own beekeeping business ||| Farmers and landowners looking to diversify their income ||| Anyone with a passion for bees and a desire to learn about the industry\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "\n",
      "--- Query: I want to learn how to start a poultry farm ---\n",
      "Answer:\n",
      "We have a perfect course for you!\n",
      "\n",
      "*   **Course Title:** Poultry Farming Course\n",
      "    *   **Description:** Egg-cellent Opportunities: Start your own Poultry Farm with our Comprehensive Business Course\n",
      "    *   **Who This Course is For:** This course is ideal for beginner farmers looking to start a poultry farming business, entrepreneurs interested in starting a poultry farming venture, and anyone looking to supplement their income by starting a poultry farm as a side business.\n",
      "    *   **Languages:** The course is available in Hindi, Kannada, Malayalam, Tamil, Telugu, and English.\n",
      "\n",
      "Documents considered:\n",
      "Course Title: Poultry Farming Course\n",
      "Description: Egg-cellent Opportunities: Start your own Poultry Farm with our Comprehensive Business Course\n",
      "Who This Course is For: Beginner farmers looking to start a poultry farming business ||| Experienced farmers looking to expand their current operations ||| Entrepreneurs interested in starting a poultry farming venture ||| Agricultural students or professionals wanting to specialize in poultry farming ||| Anyone looking to supplement their income by starting a poultry farm as a side business.\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "Course Title: Poultry Farming Course\n",
      "Description: Egg-cellent Opportunities: Start your own Poultry Farm with our Comprehensive Business Course\n",
      "Who This Course is For: Beginner farmers looking to start a poultry farming business ||| Experienced farmers looking to expand their current operations ||| Entrepreneurs interested in starting a poultry farming venture ||| Agricultural students or professionals wanting to specialize in poultry farming ||| Anyone looking to supplement their income by starting a poultry farm as a side business.\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "Course Title: Poultry Farming Course\n",
      "Description: Egg-cellent Opportunities: Start your own Poultry Farm with our Comprehensive Business Course\n",
      "Who This Course is For: Beginner farmers looking to start a poultry farming business ||| Experienced farmers looking to expand their current operations ||| Entrepreneurs interested in starting a poultry farming venture ||| Agricultural students or professionals wanting to specialize in poultry farming ||| Anyone looking to supplement their income by starting a poultry farm as a side business.\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "\n",
      "--- Query: Do you have any courses in Tamil? ---\n",
      "Answer:\n",
      "Yes, we do! We have the following course available in Tamil:\n",
      "\n",
      "*   **Course Title:** Driving School Business Course\n",
      "    *   **Description:** Accelerate your earnings: Earn big as the owner of a successful driving school!\n",
      "    *   **Who This Course is For:** Anyone interested in starting a driving school business, people who want to learn about the driving school industry and its operations, existing business owners who want to diversify their business, entrepreneurs who are interested in starting a new venture in the transportation industry, and students who are interested in learning the basics of the driving school business.\n",
      "\n",
      "Documents considered:\n",
      "Course Title: Driving School Business Course\n",
      "Description: Accelerate your earnings: Earn big as the owner of a successful driving school!\n",
      "Who This Course is For: Anyone interested in starting a driving school businessÂ  ||| People who want to learn about the driving school industry and its operations ||| Existing business owners who want to diversify their business ||| Entrepreneurs who are interested in starting a new venture in the transportation industry ||| Students who are interested in learning the basics of the driving school business\n",
      "Languages: Tamil\n",
      "------\n",
      "Course Title: Driving School Business Course\n",
      "Description: Accelerate your earnings: Earn big as the owner of a successful driving school!\n",
      "Who This Course is For: Anyone interested in starting a driving school businessÂ  ||| People who want to learn about the driving school industry and its operations ||| Existing business owners who want to diversify their business ||| Entrepreneurs who are interested in starting a new venture in the transportation industry ||| Students who are interested in learning the basics of the driving school business\n",
      "Languages: Tamil\n",
      "------\n",
      "Course Title: Driving School Business Course\n",
      "Description: Accelerate your earnings: Earn big as the owner of a successful driving school!\n",
      "Who This Course is For: Anyone interested in starting a driving school businessÂ  ||| People who want to learn about the driving school industry and its operations ||| Existing business owners who want to diversify their business ||| Entrepreneurs who are interested in starting a new venture in the transportation industry ||| Students who are interested in learning the basics of the driving school business\n",
      "Languages: Tamil\n",
      "------\n",
      "\n",
      "--- Query: I am a recent high school graduate, are there any opportunities for me? ---\n",
      "Answer:\n",
      "Yes, the **Career Building Course** is an excellent opportunity for you!\n",
      "\n",
      "This course is designed for:\n",
      "*   Individuals who are starting out in their career and want to build a solid foundation for future success.\n",
      "*   Anyone who wants to take control of their career and build the future they want.\n",
      "\n",
      "It offers a step-by-step guide to building your dream career and teaches practical, actionable strategies for success. The course is available in Hindi, Kannada, Malayalam, Tamil, Telugu, and English.\n",
      "\n",
      "Documents considered:\n",
      "Course Title: Career Building Course\n",
      "Description: Developing Your Dream Career: A Step-by-Step Guide to Building Your Dream Career\n",
      "Who This Course is For: Individuals who are starting out in their career and want to build a solid foundation for future success ||| Professionals looking to make a career change or transition into a new field ||| People who want to learn practical, actionable strategies for building a successful career ||| Job seekers who want to improve their resume and interviewing skills to increase their chances of landing a job ||| Anyone who wants to take control of their career and build the future they want.\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "Course Title: Career Building Course\n",
      "Description: Developing Your Dream Career: A Step-by-Step Guide to Building Your Dream Career\n",
      "Who This Course is For: Individuals who are starting out in their career and want to build a solid foundation for future success ||| Professionals looking to make a career change or transition into a new field ||| People who want to learn practical, actionable strategies for building a successful career ||| Job seekers who want to improve their resume and interviewing skills to increase their chances of landing a job ||| Anyone who wants to take control of their career and build the future they want.\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n",
      "Course Title: Career Building Course\n",
      "Description: Developing Your Dream Career: A Step-by-Step Guide to Building Your Dream Career\n",
      "Who This Course is For: Individuals who are starting out in their career and want to build a solid foundation for future success ||| Professionals looking to make a career change or transition into a new field ||| People who want to learn practical, actionable strategies for building a successful career ||| Job seekers who want to improve their resume and interviewing skills to increase their chances of landing a job ||| Anyone who wants to take control of their career and build the future they want.\n",
      "Languages: Hindi, Kannada, Malayalam, Tamil, Telugu, English\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 0. Install dependencies (run once)\n",
    "# ===============================\n",
    "!pip install pandas langchain chromadb sentence-transformers python-dotenv langchain-google-genai --quiet\n",
    "\n",
    "# ===============================\n",
    "# 1. Imports\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# ===============================\n",
    "# 2. Load dataset\n",
    "# ===============================\n",
    "csv_path = \"data/bw_courses - Sheet1.csv\"  # replace with your path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Quick overview\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "# ===============================\n",
    "# 3. Preprocessing\n",
    "# ===============================\n",
    "\n",
    "# Fill missing values in \"Who This Course is For\"\n",
    "df['Who This Course is For'] = df['Who This Course is For'].fillna(\"Not specified\")\n",
    "\n",
    "# Strip whitespace from all string fields\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Map language codes to names\n",
    "lang_map = {\n",
    "    6: \"Hindi\",\n",
    "    7: \"Kannada\",\n",
    "    11: \"Malayalam\",\n",
    "    20: \"Tamil\",\n",
    "    21: \"Telugu\",\n",
    "    24: \"English\"\n",
    "}\n",
    "\n",
    "def map_languages(cell):\n",
    "    codes = str(cell).split(\",\")\n",
    "    return [lang_map.get(int(c.strip()), f\"Unknown-{c.strip()}\") for c in codes]\n",
    "\n",
    "df['Released Languages'] = df['Released Languages'].apply(map_languages)\n",
    "\n",
    "# Show the 2 rows that were missing originally (for notebook demo)\n",
    "missing_rows_demo = df[df['Who This Course is For'] == \"Not specified\"]\n",
    "missing_rows_demo\n",
    "\n",
    "# ===============================\n",
    "# 4. Prepare documents with chunking\n",
    "# ===============================\n",
    "\n",
    "documents = []\n",
    "metadata_list = []\n",
    "\n",
    "MAX_TOKENS = 200  # Approximate chunk size for description\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Chunk the description if it is long\n",
    "    description_chunks = wrap(row['Course Description'], MAX_TOKENS) or [\"\"]  # fallback empty string\n",
    "    \n",
    "    for desc_chunk in description_chunks:\n",
    "        text = f\"Course Title: {row['Course Title']}\\n\" \\\n",
    "               f\"Description: {desc_chunk}\\n\" \\\n",
    "               f\"Who This Course is For: {row['Who This Course is For']}\\n\" \\\n",
    "               f\"Languages: {', '.join(row['Released Languages'])}\"\n",
    "        documents.append(text)\n",
    "        metadata_list.append({\n",
    "            \"course_no\": row['Course No'],\n",
    "            \"course_title\": row['Course Title'],\n",
    "            \"released_languages\": ', '.join(row['Released Languages']),  # join with commas\n",
    "            \"who_for\": row['Who This Course is For']\n",
    "        })\n",
    "\n",
    "\n",
    "print(f\"Total chunks created: {len(documents)}\")\n",
    "\n",
    "# ===============================\n",
    "# 5. Create embeddings & build ChromaDB\n",
    "# ===============================\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectordb = Chroma.from_texts(\n",
    "    texts=documents,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadata_list,\n",
    "    persist_directory=\"data/chroma_db\"\n",
    ")\n",
    "\n",
    "vectordb.persist()\n",
    "print(\"âœ… Chroma Vector DB created and persisted!\")\n",
    "\n",
    "# ===============================\n",
    "# 6. Setup Google Gemini LLM\n",
    "# ===============================\n",
    "load_dotenv()  # load API key from .env\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env\")\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    timeout=30,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 7. Retriever function\n",
    "# ===============================\n",
    "def get_relevant_courses(query, k=3):\n",
    "    \"\"\"\n",
    "    Retrieve top-k relevant course chunks for a query\n",
    "    \"\"\"\n",
    "    results = vectordb.similarity_search(query, k=k)\n",
    "    return [res.page_content for res in results]\n",
    "\n",
    "# ===============================\n",
    "# 8. Query function using Gemini\n",
    "# ===============================\n",
    "def generate_answer(context_docs, user_query):\n",
    "    \"\"\"\n",
    "    Use Gemini LLM to answer user queries strictly based on dataset.\n",
    "    \"\"\"\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "    prompt = f\"\"\"\n",
    "You are an AI Support Agent for **BossWallah**, specializing in answering questions\n",
    "about the available courses. Follow these rules strictly:\n",
    "\n",
    "1. Only answer using the provided dataset context. \n",
    "2. If the answer is not present in the dataset, say politely:\n",
    "   \"Sorry, I could not find a relevant course in the BossWallah catalog.\"\n",
    "3. Always include the **Course Title** and key details if available.\n",
    "4. If multiple courses are relevant, list them clearly in bullet points.\n",
    "5. If the user asks in general terms (e.g., poultry farming, financial freedom),\n",
    "   map it to the most relevant courses from the dataset.\n",
    "6. Be clear, concise, and helpful. Do not make up content beyond the dataset.\n",
    "\n",
    "---\n",
    "ğŸ“˜ Dataset Context:\n",
    "{context}\n",
    "\n",
    "---\n",
    "ğŸ’¡ User Question:\n",
    "{user_query}\n",
    "\n",
    "Now provide the best possible helpful answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_llm.invoke(prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 9. Demo: Sample queries\n",
    "# ===============================\n",
    "sample_queries = [\n",
    "    \"Tell me about honey bee farming course\",\n",
    "    \"I want to learn how to start a poultry farm\",\n",
    "    \"Do you have any courses in Tamil?\",\n",
    "    \"I am a recent high school graduate, are there any opportunities for me?\"\n",
    "]\n",
    "\n",
    "for q in sample_queries:\n",
    "    relevant_docs = get_relevant_courses(q)\n",
    "    answer = generate_answer(relevant_docs, q)\n",
    "    print(f\"\\n--- Query: {q} ---\")\n",
    "    print(\"Answer:\")\n",
    "    print(answer)\n",
    "    print(\"\\nDocuments considered:\")\n",
    "    for doc in relevant_docs:\n",
    "        print(doc)\n",
    "        print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b5f7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # make results deterministic\n",
    "\n",
    "# Map langdetect codes to your supported language names\n",
    "lang_code_map = {\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"kn\": \"Kannada\",\n",
    "    \"ta\": \"Tamil\",\n",
    "    \"te\": \"Telugu\",\n",
    "    \"ml\": \"Malayalam\",\n",
    "    \"en\": \"English\"\n",
    "}\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detects the language of the input text and maps it\n",
    "    to one of the supported languages. Defaults to English if unsupported.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        detected_code = detect(text)\n",
    "        return lang_code_map.get(detected_code, \"English\")\n",
    "    except Exception:\n",
    "        return \"English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e19a5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Malayalam'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\"\n",
    "\n",
    "detect_language(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a50db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 6. Setup Google Gemini LLM\n",
    "# ===============================\n",
    "load_dotenv()  # load API key from .env\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env\")\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    timeout=30,\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb9cb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "def translator_agent(text: str, target_lang: str) -> str:\n",
    "    \"\"\"\n",
    "    Translate English text into target language using Gemini.\n",
    "    \"\"\"\n",
    "    translation_prompt = f\"\"\"\n",
    "    You are a translation agent. Your task is to translate the following English text\n",
    "    into **{target_lang}**. Keep the meaning accurate and natural for a native speaker. \n",
    "\n",
    "    Text to translate:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    return gemini_llm.invoke(translation_prompt).content.strip()\n",
    "\n",
    "\n",
    "def translate_to_english(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Translate text from any supported language into English.\n",
    "    \"\"\"\n",
    "    translation_prompt = f\"\"\"\n",
    "    You are a translation agent. Translate the following text into **English** only. \n",
    "    Keep the meaning intact, do not summarize, just translate.\n",
    "\n",
    "    Text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    return gemini_llm.invoke(translation_prompt).content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ac80258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    End-to-end pipeline with debug logs:\n",
    "    1. Detect query language\n",
    "    2. Translate query â†’ English (if needed)\n",
    "    3. RAG Agent finds the answer in English\n",
    "    4. Translator Agent translates back to userâ€™s language\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n================ DEBUG START ================\")\n",
    "    print(f\"User Query: {user_query}\")\n",
    "\n",
    "    # Step 1: Detect query language\n",
    "    user_lang = detect_language(user_query)\n",
    "    print(f\"[DEBUG] Detected Language: {user_lang}\")\n",
    "\n",
    "    # Step 2: Translate query to English if needed\n",
    "    query_in_english = (\n",
    "        translate_to_english(user_query) if user_lang != \"English\" else user_query\n",
    "    )\n",
    "    print(f\"[DEBUG] Query in English: {query_in_english}\")\n",
    "\n",
    "    # Step 3: Retrieve relevant docs\n",
    "    relevant_docs = get_relevant_courses(query_in_english)\n",
    "    print(f\"[DEBUG] Retrieved {len(relevant_docs)} relevant docs\")\n",
    "    if relevant_docs:\n",
    "        print(\"[DEBUG] Sample Relevant Doc:\\n\", relevant_docs[0][:300], \"...\\n\")\n",
    "\n",
    "    # Step 4: Build RAG prompt\n",
    "    context = \"\\n\\n\".join(relevant_docs)\n",
    "    rag_prompt = f\"\"\"\n",
    "    Answer the user's question based on the following course information:\n",
    "    {context}\n",
    "\n",
    "    User Question: {query_in_english}\n",
    "    Answer in English:\n",
    "    \"\"\"\n",
    "    print(f\"[DEBUG] RAG Prompt:\\n{rag_prompt[:500]}...\\n\")\n",
    "\n",
    "    # Step 5: RAG Answer\n",
    "    rag_response = gemini_llm.invoke(rag_prompt).content.strip()\n",
    "    print(f\"[DEBUG] Raw RAG Response: {rag_response}\")\n",
    "\n",
    "    # Step 6: Translate back if needed\n",
    "    if user_lang != \"English\":\n",
    "        rag_response = translator_agent(rag_response, user_lang)\n",
    "        print(f\"[DEBUG] Translated Response: {rag_response}\")\n",
    "\n",
    "    print(\"================ DEBUG END ================\\n\")\n",
    "    return rag_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2ff164ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "Detected Language: Malayalam\n",
      "\n",
      "================ DEBUG START ================\n",
      "User Query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "[DEBUG] Detected Language: Malayalam\n",
      "[DEBUG] Query in English: How many cows will be needed to start a dairy farm?\n",
      "[DEBUG] Retrieved 3 relevant docs\n",
      "[DEBUG] Sample Relevant Doc:\n",
      " Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Individuals or mention a specific cat ...\n",
      "\n",
      "[DEBUG] RAG Prompt:\n",
      "\n",
      "    Answer the user's question based on the following course information:\n",
      "    Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Individuals or mention a specific category of people interested in modern dairy farming technologies ||| Entrepreneurs seeking to invest in the industry ||| S...\n",
      "\n",
      "[DEBUG] Raw RAG Response: Based on the course description, you can learn to earn substantial profit from just 10 cows.\n",
      "[DEBUG] Translated Response: \n",
      "================ DEBUG END ================\n",
      "\n",
      "Final Answer: \n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\"        # English\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nUser Query: {q}\")\n",
    "    print(\"Detected Language:\", detect_language(q))\n",
    "    print(\"Final Answer:\", generate_answer(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ecc4c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "\n",
      "================ DEBUG START ================\n",
      "User Query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "[DEBUG] Detected Language: Malayalam\n",
      "[DEBUG] Query in English: How many cows will be needed to start a dairy farm?\n",
      "[DEBUG] Retrieved 1 relevant docs\n",
      "[DEBUG] Sample Relevant Doc:\n",
      " Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in th ...\n",
      "\n",
      "[DEBUG] RAG Prompt:\n",
      "\n",
      "    Answer the user's question based on the following course information:\n",
      "    Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in the industry\n",
      "\n",
      "    User Question: How many cows will be needed to start a dairy farm?\n",
      "    Answer in English:\n",
      "    ...\n",
      "\n",
      "[DEBUG] Raw RAG Response: To earn substantial profit, the course suggests starting with 10 cows.\n",
      "[DEBUG] Translated Response: à´—à´£àµà´¯à´®à´¾à´¯ à´²à´¾à´­à´‚ à´¨àµ‡à´Ÿàµà´¨àµà´¨à´¤à´¿à´¨àµ, 10 à´ªà´¶àµà´•àµà´•à´³àµà´®à´¾à´¯à´¿ à´¤àµà´Ÿà´™àµà´™à´¾àµ» à´•àµ‹à´´àµà´¸àµ à´¨à´¿àµ¼à´¦àµà´¦àµ‡à´¶à´¿à´•àµà´•àµà´¨àµà´¨àµ.\n",
      "================ DEBUG END ================\n",
      "\n",
      "Final Answer: à´—à´£àµà´¯à´®à´¾à´¯ à´²à´¾à´­à´‚ à´¨àµ‡à´Ÿàµà´¨àµà´¨à´¤à´¿à´¨àµ, 10 à´ªà´¶àµà´•àµà´•à´³àµà´®à´¾à´¯à´¿ à´¤àµà´Ÿà´™àµà´™à´¾àµ» à´•àµ‹à´´àµà´¸àµ à´¨à´¿àµ¼à´¦àµà´¦àµ‡à´¶à´¿à´•àµà´•àµà´¨àµà´¨àµ.\n",
      "__________________________________\n",
      "\n",
      "User Query: à¤ªà¥‹à¤²à¥à¤Ÿà¥à¤°à¥€ à¤«à¤¾à¤°à¥à¤® à¤•à¥ˆà¤¸à¥‡ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚?\n",
      "\n",
      "================ DEBUG START ================\n",
      "User Query: à¤ªà¥‹à¤²à¥à¤Ÿà¥à¤°à¥€ à¤«à¤¾à¤°à¥à¤® à¤•à¥ˆà¤¸à¥‡ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚?\n",
      "[DEBUG] Detected Language: Hindi\n",
      "[DEBUG] Query in English: How to start a poultry farm?\n",
      "[DEBUG] Retrieved 1 relevant docs\n",
      "[DEBUG] Sample Relevant Doc:\n",
      " Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in th ...\n",
      "\n",
      "[DEBUG] RAG Prompt:\n",
      "\n",
      "    Answer the user's question based on the following course information:\n",
      "    Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in the industry\n",
      "\n",
      "    User Question: How to start a poultry farm?\n",
      "    Answer in English:\n",
      "    ...\n",
      "\n",
      "[DEBUG] Raw RAG Response: The provided course information is about \"Dairy Farming Course\" and does not contain any details on how to start a poultry farm.\n",
      "[DEBUG] Translated Response: à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¥€ à¤—à¤ˆ à¤ªà¤¾à¤ à¥à¤¯à¤•à¥à¤°à¤® à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ 'à¤¡à¥‡à¤¯à¤°à¥€ à¤«à¤¾à¤°à¥à¤®à¤¿à¤‚à¤— à¤•à¥‹à¤°à¥à¤¸' à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¤®à¥‡à¤‚ à¤ªà¥‹à¤²à¥à¤Ÿà¥à¤°à¥€ à¤«à¤¾à¤°à¥à¤® à¤•à¥ˆà¤¸à¥‡ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚, à¤‡à¤¸ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤•à¥‹à¤ˆ à¤µà¤¿à¤µà¤°à¤£ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¥¤\n",
      "================ DEBUG END ================\n",
      "\n",
      "Final Answer: à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¥€ à¤—à¤ˆ à¤ªà¤¾à¤ à¥à¤¯à¤•à¥à¤°à¤® à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ 'à¤¡à¥‡à¤¯à¤°à¥€ à¤«à¤¾à¤°à¥à¤®à¤¿à¤‚à¤— à¤•à¥‹à¤°à¥à¤¸' à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ à¤”à¤° à¤‡à¤¸à¤®à¥‡à¤‚ à¤ªà¥‹à¤²à¥à¤Ÿà¥à¤°à¥€ à¤«à¤¾à¤°à¥à¤® à¤•à¥ˆà¤¸à¥‡ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚, à¤‡à¤¸ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤•à¥‹à¤ˆ à¤µà¤¿à¤µà¤°à¤£ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¥¤\n",
      "__________________________________\n",
      "\n",
      "User Query: Can you tell me about the honey bee farming course?\n",
      "\n",
      "================ DEBUG START ================\n",
      "User Query: Can you tell me about the honey bee farming course?\n",
      "[DEBUG] Detected Language: English\n",
      "[DEBUG] Query in English: Can you tell me about the honey bee farming course?\n",
      "[DEBUG] Retrieved 1 relevant docs\n",
      "[DEBUG] Sample Relevant Doc:\n",
      " Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in th ...\n",
      "\n",
      "[DEBUG] RAG Prompt:\n",
      "\n",
      "    Answer the user's question based on the following course information:\n",
      "    Course Title: Dairy Farming Course\n",
      "Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\n",
      "Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in the industry\n",
      "\n",
      "    User Question: Can you tell me about the honey bee farming course?\n",
      "    Answer in English:\n",
      "    ...\n",
      "\n",
      "[DEBUG] Raw RAG Response: I'm sorry, but I don't have any information about a honey bee farming course. The course information provided is for a **Dairy Farming Course**.\n",
      "================ DEBUG END ================\n",
      "\n",
      "Final Answer: I'm sorry, but I don't have any information about a honey bee farming course. The course information provided is for a **Dairy Farming Course**.\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ğŸ”¹ Imports\n",
    "# ============================================\n",
    "import os\n",
    "from langdetect import detect\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ğŸ”¹ Language Detection\n",
    "# ============================================\n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detect the language of the given text using langdetect.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lang_code = detect(text)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Language detection failed: {e}\")\n",
    "        return \"English\"\n",
    "\n",
    "    lang_map = {\n",
    "        \"te\": \"Telugu\",\n",
    "        \"hi\": \"Hindi\",\n",
    "        \"kn\": \"Kannada\",\n",
    "        \"ta\": \"Tamil\",\n",
    "        \"ml\": \"Malayalam\",\n",
    "        \"en\": \"English\",\n",
    "    }\n",
    "    return lang_map.get(lang_code, \"English\")\n",
    "\n",
    "# ============================================\n",
    "# ğŸ”¹ Translator (Bi-directional)\n",
    "# ============================================\n",
    "def translate_text(text: str, target_lang: str) -> str:\n",
    "    \"\"\"\n",
    "    Translate text into the target language using Gemini.\n",
    "    If target_lang = 'English', ensures output is English.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a strict translation agent.\n",
    "    Translate the following text into {target_lang}.\n",
    "    Do not explain, do not summarize, do not add anything extra.\n",
    "    Return only the translated text.\n",
    "\n",
    "    Text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = gemini_llm.invoke(prompt)\n",
    "        if hasattr(response, \"content\") and response.content:\n",
    "            return response.content.strip()\n",
    "        else:\n",
    "            return str(response).strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Translation failed: {e}\")\n",
    "        return text  # fallback\n",
    "\n",
    "# ============================================\n",
    "# ğŸ”¹ Dummy Retriever (replace with vectorstore retrieval)\n",
    "# ============================================\n",
    "def get_relevant_courses(query: str):\n",
    "    \"\"\"\n",
    "    Mock retriever: in real app, fetch relevant docs from vectorstore (ChromaDB).\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"Course Title: Dairy Farming Course\\n\"\n",
    "        \"Description: Ready to milk your potential? Learn the art of dairy farming and earn substantial profit from just 10 cows.\\n\"\n",
    "        \"Who This Course is For: Farmers looking for new income streams ||| Aspiring dairy farm business owners ||| Entrepreneurs seeking to invest in the industry\"\n",
    "    ]\n",
    "\n",
    "# ============================================\n",
    "# ğŸ”¹ Main Pipeline\n",
    "# ============================================\n",
    "def generate_answer(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    End-to-end pipeline with debug logs:\n",
    "    1. Detect query language\n",
    "    2. Translate query â†’ English (if needed)\n",
    "    3. RAG Agent finds the answer in English\n",
    "    4. Translate answer back to userâ€™s language\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n================ DEBUG START ================\")\n",
    "    print(f\"User Query: {user_query}\")\n",
    "\n",
    "    # Step 1: Detect query language\n",
    "    user_lang = detect_language(user_query)\n",
    "    print(f\"[DEBUG] Detected Language: {user_lang}\")\n",
    "\n",
    "    # Step 2: Translate query to English if needed\n",
    "    query_in_english = (\n",
    "        translate_text(user_query, \"English\") if user_lang != \"English\" else user_query\n",
    "    )\n",
    "    print(f\"[DEBUG] Query in English: {query_in_english}\")\n",
    "\n",
    "    # Step 3: Retrieve relevant docs\n",
    "    relevant_docs = get_relevant_courses(query_in_english)\n",
    "    print(f\"[DEBUG] Retrieved {len(relevant_docs)} relevant docs\")\n",
    "    if relevant_docs:\n",
    "        print(\"[DEBUG] Sample Relevant Doc:\\n\", relevant_docs[0][:300], \"...\\n\")\n",
    "\n",
    "    # Step 4: Build RAG prompt\n",
    "    context = \"\\n\\n\".join(relevant_docs)\n",
    "    rag_prompt = f\"\"\"\n",
    "    Answer the user's question based on the following course information:\n",
    "    {context}\n",
    "\n",
    "    User Question: {query_in_english}\n",
    "    Answer in English:\n",
    "    \"\"\"\n",
    "    print(f\"[DEBUG] RAG Prompt:\\n{rag_prompt[:500]}...\\n\")\n",
    "\n",
    "    # Step 5: Get RAG Answer\n",
    "    try:\n",
    "        rag_response = gemini_llm.invoke(rag_prompt).content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] RAG generation failed: {e}\")\n",
    "        rag_response = \"Sorry, I could not generate an answer.\"\n",
    "\n",
    "    print(f\"[DEBUG] Raw RAG Response: {rag_response}\")\n",
    "\n",
    "    # Step 6: Translate back to original language if needed\n",
    "    if user_lang != \"English\":\n",
    "        rag_response_translated = translate_text(rag_response, user_lang)\n",
    "        print(f\"[DEBUG] Translated Response: {rag_response_translated}\")\n",
    "        rag_response = rag_response_translated\n",
    "\n",
    "    print(\"================ DEBUG END ================\\n\")\n",
    "    return rag_response\n",
    "\n",
    "# ============================================\n",
    "# ğŸ”¹ Test\n",
    "# ============================================\n",
    "queries = [\n",
    "    \"à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\",  # Malayalam\n",
    "    \"à¤ªà¥‹à¤²à¥à¤Ÿà¥à¤°à¥€ à¤«à¤¾à¤°à¥à¤® à¤•à¥ˆà¤¸à¥‡ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚?\",                       # Hindi\n",
    "    \"Can you tell me about the honey bee farming course?\"   # English\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nUser Query: {q}\")\n",
    "    print(\"Final Answer:\", generate_answer(q))\n",
    "    print(\"__________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b70195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "Total chunks created: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_19032\\2443363960.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chroma Vector DB created and persisted!\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 0. Install dependencies (run once)\n",
    "# ===============================\n",
    "# !pip install pandas langchain chromadb sentence-transformers python-dotenv langchain-google-genai langdetect --quiet\n",
    "\n",
    "# ===============================\n",
    "# 1. Imports\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langdetect import detect\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# ===============================\n",
    "# 2. Load dataset\n",
    "# ===============================\n",
    "csv_path = \"data/bw_courses - Sheet1.csv\"  # replace with your path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Quick overview\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "# ===============================\n",
    "# 3. Preprocessing\n",
    "# ===============================\n",
    "df['Who This Course is For'] = df['Who This Course is For'].fillna(\"Not specified\")\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "lang_map = {\n",
    "    6: \"Hindi\",\n",
    "    7: \"Kannada\",\n",
    "    11: \"Malayalam\",\n",
    "    20: \"Tamil\",\n",
    "    21: \"Telugu\",\n",
    "    24: \"English\"\n",
    "}\n",
    "\n",
    "def map_languages(cell):\n",
    "    codes = str(cell).split(\",\")\n",
    "    return [lang_map.get(int(c.strip()), f\"Unknown-{c.strip()}\") for c in codes]\n",
    "\n",
    "df['Released Languages'] = df['Released Languages'].apply(map_languages)\n",
    "\n",
    "# Show the missing rows demo\n",
    "missing_rows_demo = df[df['Who This Course is For'] == \"Not specified\"]\n",
    "missing_rows_demo\n",
    "\n",
    "# ===============================\n",
    "# 4. Prepare documents with chunking\n",
    "# ===============================\n",
    "documents = []\n",
    "metadata_list = []\n",
    "MAX_TOKENS = 200  \n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    description_chunks = wrap(row['Course Description'], MAX_TOKENS) or [\"\"]\n",
    "\n",
    "    for desc_chunk in description_chunks:\n",
    "        text = f\"Course Title: {row['Course Title']}\\n\" \\\n",
    "               f\"Description: {desc_chunk}\\n\" \\\n",
    "               f\"Who This Course is For: {row['Who This Course is For']}\\n\" \\\n",
    "               f\"Languages: {', '.join(row['Released Languages'])}\"\n",
    "        documents.append(text)\n",
    "        metadata_list.append({\n",
    "            \"course_no\": row['Course No'],\n",
    "            \"course_title\": row['Course Title'],\n",
    "            \"released_languages\": ', '.join(row['Released Languages']),\n",
    "            \"who_for\": row['Who This Course is For']\n",
    "        })\n",
    "\n",
    "print(f\"Total chunks created: {len(documents)}\")\n",
    "\n",
    "# ===============================\n",
    "# 5. Create embeddings & build ChromaDB\n",
    "# ===============================\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectordb = Chroma.from_texts(\n",
    "    texts=documents,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadata_list,\n",
    "    persist_directory=\"data/chroma_db\"\n",
    ")\n",
    "\n",
    "vectordb.persist()\n",
    "print(\"âœ… Chroma Vector DB created and persisted!\")\n",
    "\n",
    "# ===============================\n",
    "# 6. Setup Google Gemini LLM\n",
    "# ===============================\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env\")\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    timeout=30,\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba186642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ User: Which courses are available in Tamil?\n",
      "ğŸ” Detected language: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_19032\\2750650797.py:40: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(translated_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– RAG Answer: *   Course on National Pension Scheme\n",
      "*   Education Loan Course\n",
      "================================================================================\n",
      "ğŸ’¬ User: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "ğŸ” Detected language: ml\n",
      "ğŸŒ Translated query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "ğŸ¤– RAG Answer: à´ˆ à´šàµ‹à´¯àµà´¸àµ à´¤à´¤àµà´¤àµà´²àµà´¯à´®à´¾à´¯ à´‰àµ½à´ªà´¨àµà´¨à´™àµà´™àµ¾ à´¨àµ½à´•àµà´¨àµà´¨à´¤à´¿àµ½ à´ªà´°à´¾à´œà´¯à´ªàµà´ªàµ†à´Ÿàµà´Ÿà´¾àµ½ à´•àµ‹à´³à´¿à´«àµà´³à´µàµ¼ à´²à´­àµà´¯à´®à´²àµà´². à´‡à´¨àµâ€à´·àµà´±à´¨àµâ€à´¸àµ à´ªàµ‹à´³à´¿à´¸à´¿à´ªàµ‹à´³à´¿à´¸à´¿ à´à´Ÿàµà´•àµà´•àµà´•.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 7. Translation & Language Handling\n",
    "# ===============================\n",
    "from translate import Translator\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"Detect query language using langdetect.\"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"en\"  # default to English if uncertain\n",
    "\n",
    "def translate_text(text: str, target_lang: str) -> str:\n",
    "    \"\"\"Translate text using translate library.\"\"\"\n",
    "    try:\n",
    "        translator = Translator(to_lang=target_lang)\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Translation error: {e}\")\n",
    "        return text  # fallback to original text if error\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 8. RAG Query Function\n",
    "# ===============================\n",
    "def rag_query(user_query: str):\n",
    "    # Step 1: Detect input language\n",
    "    query_lang = detect_language(user_query)\n",
    "    print(f\"ğŸ” Detected language: {query_lang}\")\n",
    "\n",
    "    # Step 2: If not English, translate to English\n",
    "    if query_lang != \"en\":\n",
    "        translated_query = translate_text(user_query, \"en\")\n",
    "        print(f\"ğŸŒ Translated query: {translated_query}\")\n",
    "    else:\n",
    "        translated_query = user_query\n",
    "\n",
    "    # Step 3: Perform retrieval\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "    docs = retriever.get_relevant_documents(translated_query)\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant helping users understand course details. \n",
    "    Use the context below to answer the query.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {translated_query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 4: Get response from Gemini\n",
    "    response = gemini_llm.invoke(prompt)\n",
    "    rag_answer = response.content.strip()\n",
    "\n",
    "    # Step 5: If original query language â‰  English, translate response back\n",
    "    if query_lang != \"en\":\n",
    "        rag_answer_translated = translate_text(rag_answer, query_lang)\n",
    "        return rag_answer_translated\n",
    "\n",
    "    return rag_answer\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 9. Example Run\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    # Example in English\n",
    "    q1 = \"Which courses are available in Tamil?\"\n",
    "    print(\"ğŸ’¬ User:\", q1)\n",
    "    print(\"ğŸ¤– RAG Answer:\", rag_query(q1))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Example in Hindi\n",
    "    q2 = \"à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\"\n",
    "    print(\"ğŸ’¬ User:\", q2)\n",
    "    print(\"ğŸ¤– RAG Answer:\", rag_query(q2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f751e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Initializing Multilingual RAG Pipeline...\n",
      "ğŸ”§ Setting up Gemini LLM...\n",
      "ğŸ“ Loading course data...\n",
      "âœ… Loaded 100 courses\n",
      "ğŸ” Creating vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_19032\\206077131.py:105: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector database created and persisted!\n",
      "ğŸ‰ Pipeline initialization complete!\n",
      "================================================================================\n",
      "ğŸ’¬ User Query: Which courses are available in Tamil?\n",
      "----------------------------------------\n",
      "ğŸ” Processing query: Which courses are available in Tamil?...\n",
      "ğŸŒ Detected language: English (en)\n",
      "ğŸ” Searching for relevant courses...\n",
      "ğŸ¤– Generating response...\n",
      "ğŸŒ Detected Language: English\n",
      "ğŸ“š Retrieved Documents: 3\n",
      "ğŸ¤– Answer: Based on the provided context, the following courses are available in Tamil:\n",
      "\n",
      "*   **Course on National Pension Scheme**\n",
      "*   **Education Loan Course**\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ User Query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "----------------------------------------\n",
      "ğŸ” Processing query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚...\n",
      "ğŸŒ Detected language: Malayalam (ml)\n",
      "ğŸ”„ Translating query to English...\n",
      "ğŸ“ English query: How many cows are needed to start a dairy farm?\n",
      "ğŸ” Searching for relevant courses...\n",
      "ğŸ¤– Generating response...\n",
      "ğŸ”„ Translating response to Malayalam...\n",
      "ğŸŒ Detected Language: Malayalam\n",
      "ğŸ“š Retrieved Documents: 3\n",
      "ğŸ¤– Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Improved Multilingual RAG Pipeline\n",
    "# ===============================\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Set seed for consistent language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# ===============================\n",
    "# Enhanced Language Detection & Translation\n",
    "# ===============================\n",
    "\n",
    "# Language mappings for Indian languages\n",
    "LANGUAGE_MAPPINGS = {\n",
    "    'ml': 'Malayalam',\n",
    "    'hi': 'Hindi', \n",
    "    'ta': 'Tamil',\n",
    "    'te': 'Telugu',\n",
    "    'kn': 'Kannada',\n",
    "    'en': 'English'\n",
    "}\n",
    "\n",
    "SUPPORTED_LANGUAGES = {'ml', 'hi', 'ta', 'te', 'kn', 'en'}\n",
    "\n",
    "def enhanced_language_detection(text: str) -> str:\n",
    "    \"\"\"Enhanced language detection with fallbacks for Indian languages.\"\"\"\n",
    "    \n",
    "    # Simple script-based detection for better accuracy\n",
    "    def detect_by_script(text):\n",
    "        # Malayalam Unicode range\n",
    "        if re.search(r'[\\u0D00-\\u0D7F]', text):\n",
    "            return 'ml'\n",
    "        # Hindi/Devanagari Unicode range\n",
    "        elif re.search(r'[\\u0900-\\u097F]', text):\n",
    "            return 'hi'\n",
    "        # Tamil Unicode range\n",
    "        elif re.search(r'[\\u0B80-\\u0BFF]', text):\n",
    "            return 'ta'\n",
    "        # Telugu Unicode range\n",
    "        elif re.search(r'[\\u0C00-\\u0C7F]', text):\n",
    "            return 'te'\n",
    "        # Kannada Unicode range\n",
    "        elif re.search(r'[\\u0C80-\\u0CFF]', text):\n",
    "            return 'kn'\n",
    "        return None\n",
    "    \n",
    "    # Try script-based detection first\n",
    "    script_lang = detect_by_script(text)\n",
    "    if script_lang:\n",
    "        return script_lang\n",
    "    \n",
    "    # Fallback to langdetect\n",
    "    try:\n",
    "        detected = detect(text)\n",
    "        return detected if detected in SUPPORTED_LANGUAGES else 'en'\n",
    "    except:\n",
    "        return 'en'\n",
    "\n",
    "def translate_with_gemini(text: str, target_lang: str, source_lang: str = 'en') -> str:\n",
    "    \"\"\"Use Gemini for translation with proper language names.\"\"\"\n",
    "    \n",
    "    if source_lang == target_lang:\n",
    "        return text\n",
    "    \n",
    "    source_name = LANGUAGE_MAPPINGS.get(source_lang, 'English')\n",
    "    target_name = LANGUAGE_MAPPINGS.get(target_lang, 'English')\n",
    "    \n",
    "    translation_prompt = f\"\"\"\n",
    "    Translate the following text from {source_name} to {target_name}.\n",
    "    Provide only the translation, no explanations or additional text.\n",
    "    \n",
    "    Text to translate: {text}\n",
    "    \n",
    "    Translation:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the same gemini_llm instance\n",
    "        response = gemini_llm.invoke(translation_prompt)\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Gemini translation error: {e}\")\n",
    "        return text\n",
    "\n",
    "# ===============================\n",
    "# Data Loading and Processing (Same as before)\n",
    "# ===============================\n",
    "\n",
    "def load_and_process_data(csv_path: str):\n",
    "    \"\"\"Load and preprocess the course data.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['Who This Course is For'] = df['Who This Course is For'].fillna(\"Not specified\")\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    # Language mapping\n",
    "    lang_map = {\n",
    "        6: \"Hindi\",\n",
    "        7: \"Kannada\", \n",
    "        11: \"Malayalam\",\n",
    "        20: \"Tamil\",\n",
    "        21: \"Telugu\",\n",
    "        24: \"English\"\n",
    "    }\n",
    "    \n",
    "    def map_languages(cell):\n",
    "        codes = str(cell).split(\",\")\n",
    "        return [lang_map.get(int(c.strip()), f\"Unknown-{c.strip()}\") for c in codes]\n",
    "    \n",
    "    df['Released Languages'] = df['Released Languages'].apply(map_languages)\n",
    "    return df\n",
    "\n",
    "def create_documents_and_vectordb(df, persist_dir: str = \"data/chroma_db\"):\n",
    "    \"\"\"Create document chunks and build vector database.\"\"\"\n",
    "    documents = []\n",
    "    metadata_list = []\n",
    "    MAX_TOKENS = 200\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        description_chunks = wrap(row['Course Description'], MAX_TOKENS) or [\"\"]\n",
    "        \n",
    "        for desc_chunk in description_chunks:\n",
    "            text = f\"Course Title: {row['Course Title']}\\n\" \\\n",
    "                   f\"Description: {desc_chunk}\\n\" \\\n",
    "                   f\"Who This Course is For: {row['Who This Course is For']}\\n\" \\\n",
    "                   f\"Languages: {', '.join(row['Released Languages'])}\"\n",
    "            documents.append(text)\n",
    "            metadata_list.append({\n",
    "                \"course_no\": row['Course No'],\n",
    "                \"course_title\": row['Course Title'], \n",
    "                \"released_languages\": ', '.join(row['Released Languages']),\n",
    "                \"who_for\": row['Who This Course is For']\n",
    "            })\n",
    "    \n",
    "    # Create embeddings\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    vectordb = Chroma.from_texts(\n",
    "        texts=documents,\n",
    "        embedding=embedding_model,\n",
    "        metadatas=metadata_list,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    \n",
    "    vectordb.persist()\n",
    "    return vectordb\n",
    "\n",
    "# ===============================\n",
    "# Setup LLM\n",
    "# ===============================\n",
    "\n",
    "def setup_gemini_llm():\n",
    "    \"\"\"Initialize Gemini LLM.\"\"\"\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "    \n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        google_api_key=api_key,\n",
    "        temperature=0.0,\n",
    "        max_tokens=512,\n",
    "        timeout=30,\n",
    "        max_retries=3\n",
    "    )\n",
    "\n",
    "# ===============================\n",
    "# Enhanced RAG Query Function\n",
    "# ===============================\n",
    "\n",
    "def enhanced_rag_query(user_query: str, vectordb, llm):\n",
    "    \"\"\"\n",
    "    Enhanced RAG query with improved multilingual support.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Processing query: {user_query[:50]}...\")\n",
    "    \n",
    "    # Step 1: Enhanced language detection\n",
    "    query_lang = enhanced_language_detection(user_query)\n",
    "    lang_name = LANGUAGE_MAPPINGS.get(query_lang, 'Unknown')\n",
    "    print(f\"ğŸŒ Detected language: {lang_name} ({query_lang})\")\n",
    "    \n",
    "    # Step 2: Translate to English for retrieval if needed\n",
    "    if query_lang != 'en':\n",
    "        print(\"ğŸ”„ Translating query to English...\")\n",
    "        english_query = translate_with_gemini(user_query, 'en', query_lang)\n",
    "        print(f\"ğŸ“ English query: {english_query}\")\n",
    "    else:\n",
    "        english_query = user_query\n",
    "    \n",
    "    # Step 3: Retrieve relevant documents\n",
    "    print(\"ğŸ” Searching for relevant courses...\")\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "    docs = retriever.get_relevant_documents(english_query)\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Step 4: Generate response\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant for Boswallah courses. Use the provided context to answer the user's question accurately and helpfully.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {english_query}\n",
    "    \n",
    "    Please provide a comprehensive answer based on the context. If the context doesn't contain enough information, mention that clearly.\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ¤– Generating response...\")\n",
    "    response = llm.invoke(prompt)\n",
    "    english_answer = response.content.strip()\n",
    "    \n",
    "    # Step 5: Translate response back to original language if needed\n",
    "    if query_lang != 'en':\n",
    "        print(f\"ğŸ”„ Translating response to {lang_name}...\")\n",
    "        final_answer = translate_with_gemini(english_answer, query_lang, 'en')\n",
    "    else:\n",
    "        final_answer = english_answer\n",
    "    \n",
    "    return {\n",
    "        'query': user_query,\n",
    "        'detected_language': lang_name,\n",
    "        'answer': final_answer,\n",
    "        'retrieved_docs': len(docs)\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# Main Pipeline Class\n",
    "# ===============================\n",
    "\n",
    "class MultilingualRAGPipeline:\n",
    "    \"\"\"Complete multilingual RAG pipeline for Boswallah courses.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path: str, persist_dir: str = \"data/chroma_db\"):\n",
    "        self.csv_path = csv_path\n",
    "        self.persist_dir = persist_dir\n",
    "        self.vectordb = None\n",
    "        self.llm = None\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the pipeline.\"\"\"\n",
    "        print(\"ğŸš€ Initializing Multilingual RAG Pipeline...\")\n",
    "        \n",
    "        # Setup LLM\n",
    "        print(\"ğŸ”§ Setting up Gemini LLM...\")\n",
    "        self.llm = setup_gemini_llm()\n",
    "        \n",
    "        # Load and process data\n",
    "        print(\"ğŸ“ Loading course data...\")\n",
    "        df = load_and_process_data(self.csv_path)\n",
    "        print(f\"âœ… Loaded {len(df)} courses\")\n",
    "        \n",
    "        # Create vector database\n",
    "        print(\"ğŸ” Creating vector database...\")\n",
    "        self.vectordb = create_documents_and_vectordb(df, self.persist_dir)\n",
    "        print(\"âœ… Vector database created and persisted!\")\n",
    "        \n",
    "        # Set global LLM for translation functions\n",
    "        global gemini_llm\n",
    "        gemini_llm = self.llm\n",
    "        \n",
    "        print(\"ğŸ‰ Pipeline initialization complete!\")\n",
    "    \n",
    "    def query(self, user_query: str):\n",
    "        \"\"\"Process a user query.\"\"\"\n",
    "        if not self.vectordb or not self.llm:\n",
    "            raise ValueError(\"Pipeline not initialized. Call initialize() first.\")\n",
    "        \n",
    "        return enhanced_rag_query(user_query, self.vectordb, self.llm)\n",
    "\n",
    "# ===============================\n",
    "# Usage Example\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize pipeline\n",
    "    pipeline = MultilingualRAGPipeline(\"data/bw_courses - Sheet1.csv\")\n",
    "    pipeline.initialize()\n",
    "    \n",
    "    # Test queries in different languages\n",
    "    test_queries = [\n",
    "        \"Which courses are available in Tamil?\",\n",
    "        \"à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\",  # Malayalam\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"ğŸ’¬ User Query: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            result = pipeline.query(query)\n",
    "            print(f\"ğŸŒ Detected Language: {result['detected_language']}\")\n",
    "            print(f\"ğŸ“š Retrieved Documents: {result['retrieved_docs']}\")\n",
    "            print(f\"ğŸ¤– Answer: {result['answer']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "467d6bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Initializing Multilingual RAG Pipeline...\n",
      "ğŸ”§ Setting up Gemini LLM...\n",
      "ğŸ“ Loading course data...\n",
      "âœ… Loaded 100 courses\n",
      "ğŸ” Creating vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_19032\\235149990.py:189: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector database created and persisted!\n",
      "ğŸ‰ Pipeline initialization complete!\n",
      "================================================================================\n",
      "TEST 1: Which courses are available in Tamil?\n",
      "----------------------------------------\n",
      "ğŸ” Processing query: Which courses are available in Tamil?...\n",
      "ğŸŒ Detected language: English (en)\n",
      "ğŸ” Searching for relevant courses...\n",
      "ğŸ“„ Retrieved context length: 1906 characters\n",
      "ğŸ¤– Generating response...\n",
      "âœ… Generated English answer: Based on the provided course information, the following courses are available in Tamil:\n",
      "\n",
      "*   **Course on National Pension Scheme:** This course is des...\n",
      "ğŸŒ Detected Language: English\n",
      "ğŸ“š Retrieved Documents: 3\n",
      "ğŸ” English Query: Which courses are available in Tamil?\n",
      "ğŸ”¤ English Answer: Based on the provided course information, the following courses are available in Tamil:\n",
      "\n",
      "*   **Course on National Pension Scheme:** This course is designed to help you make your golden years truly gol...\n",
      "ğŸ¤– Final Answer: Based on the provided course information, the following courses are available in Tamil:\n",
      "\n",
      "*   **Course on National Pension Scheme:** This course is designed to help you make your golden years truly golden by providing an in-depth understanding of the National Pension System (NPS), including how it works, different account types, benefits (like tax benefits and investment options), how to use the NPS calculator, and how to make contributions and withdrawals.\n",
      "*   **Education Loan Course:** This course empowers your education journey by providing information on securing collateral-free loans for substantial financial support. It is suitable for students seeking funding, parents, individuals interested in the loan process and eligibility, and professionals in the education or finance sectors.\n",
      "\n",
      "================================================================================\n",
      "TEST 2: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "----------------------------------------\n",
      "ğŸ” Processing query: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚...\n",
      "ğŸŒ Detected language: Malayalam (ml)\n",
      "ğŸ”„ Translating query to English...\n",
      "ğŸ”„ Translating from Malayalam to English...\n",
      "ğŸ“ Original text: à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\n",
      "âœ… Translation result: How many cows need to be able to start a Daery Farm?\n",
      "ğŸ“ English query: How many cows need to be able to start a Daery Farm?\n",
      "ğŸ” Searching for relevant courses...\n",
      "ğŸ“„ Retrieved context length: 1585 characters\n",
      "ğŸ¤– Generating response...\n",
      "âœ… Generated English answer: Based on the \"Dairy Farming Course\" information provided by Boswallah, the course teaches how to earn substantial profit from **just 10 cows**. This s...\n",
      "ğŸ”„ Translating response back to Malayalam...\n",
      "ğŸ”„ Translating from English to Malayalam...\n",
      "ğŸ“ Original text: Based on the \"Dairy Farming Course\" information provided by Boswallah, the course teaches how to ear...\n",
      "âœ… Translation result: à´¬àµ‹à´¸àµà´µà´²àµà´² à´¨àµ½à´•àµà´¨àµà´¨ \"à´¡à´¯à´±à´¿ à´•à´¾àµ¼à´·à´¿à´• à´—à´¤à´¿\" à´…à´Ÿà´¿à´¸àµà´¥à´¾à´¨à´®à´¾à´•àµà´•à´¿, à´¬àµ‹à´¸àµà´µà´²àµà´² à´¨àµ½à´•àµà´¨àµà´¨ à´µà´¿à´µà´°à´™àµà´™à´³àµà´Ÿàµ† à´…à´Ÿà´¿à´¸àµà´¥à´¾à´¨à´¤àµà´¤à´¿àµ½, ** à´µàµ†...\n",
      "ğŸŒ Detected Language: Malayalam\n",
      "ğŸ“š Retrieved Documents: 3\n",
      "ğŸ” English Query: How many cows need to be able to start a Daery Farm?\n",
      "ğŸ”¤ English Answer: Based on the \"Dairy Farming Course\" information provided by Boswallah, the course teaches how to earn substantial profit from **just 10 cows**. This suggests that a dairy farm can be started with as f...\n",
      "ğŸ¤– Final Answer: à´¬àµ‹à´¸àµà´µà´²àµà´² à´¨àµ½à´•àµà´¨àµà´¨ \"à´¡à´¯à´±à´¿ à´•à´¾àµ¼à´·à´¿à´• à´—à´¤à´¿\" à´…à´Ÿà´¿à´¸àµà´¥à´¾à´¨à´®à´¾à´•àµà´•à´¿, à´¬àµ‹à´¸àµà´µà´²àµà´² à´¨àµ½à´•àµà´¨àµà´¨ à´µà´¿à´µà´°à´™àµà´™à´³àµà´Ÿàµ† à´…à´Ÿà´¿à´¸àµà´¥à´¾à´¨à´¤àµà´¤à´¿àµ½, ** à´µàµ†à´±àµà´‚ 10 à´ªà´¶àµà´•àµà´•à´³à´¿àµ½ à´¨à´¿à´¨àµà´¨àµ à´—à´£àµà´¯à´®à´¾à´¯ à´²à´¾à´­à´‚ à´¨àµ‡à´Ÿà´¾à´®àµ†à´¨àµà´¨àµ à´•àµ‹à´´àµà´¸àµ à´ªà´ à´¿à´ªàµà´ªà´¿à´•àµà´•àµà´¨àµà´¨àµ **.à´—à´¤à´¿à´¯àµà´Ÿàµ† à´ªà´¾à´ àµà´¯à´ªà´¦àµà´§à´¤à´¿ à´ªàµà´°à´•à´¾à´°à´‚ à´’à´°àµ à´•àµà´·àµ€à´° à´«à´¾à´‚ 10 à´ªà´¶àµà´•àµà´•à´³àµ‹à´Ÿàµ† 10 à´ªà´¶àµà´•àµà´•à´³àµ‹à´Ÿàµ† à´†à´°à´‚à´­à´¿à´•àµà´•àµà´®àµ†à´¨àµà´¨àµ à´‡à´¤àµ à´¸àµ‚à´šà´¿à´ªàµà´ªà´¿à´•àµà´•àµà´¨àµà´¨àµ.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Complete Multilingual RAG Pipeline with Google Translate\n",
    "# ===============================\n",
    "\n",
    "# First install required packages:\n",
    "# pip install pandas langchain chromadb sentence-transformers python-dotenv langchain-google-genai langdetect googletrans==4.0.0rc1\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from googletrans import Translator\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Set seed for consistent language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# ===============================\n",
    "# Language Detection & Translation\n",
    "# ===============================\n",
    "\n",
    "# Language mappings for Indian languages\n",
    "LANGUAGE_MAPPINGS = {\n",
    "    'ml': 'Malayalam',\n",
    "    'hi': 'Hindi', \n",
    "    'ta': 'Tamil',\n",
    "    'te': 'Telugu',\n",
    "    'kn': 'Kannada',\n",
    "    'en': 'English'\n",
    "}\n",
    "\n",
    "SUPPORTED_LANGUAGES = {'ml', 'hi', 'ta', 'te', 'kn', 'en'}\n",
    "\n",
    "# Google Translate language codes\n",
    "GOOGLE_LANG_CODES = {\n",
    "    'ml': 'ml',  # Malayalam\n",
    "    'hi': 'hi',  # Hindi\n",
    "    'ta': 'ta',  # Tamil\n",
    "    'te': 'te',  # Telugu\n",
    "    'kn': 'kn',  # Kannada\n",
    "    'en': 'en'   # English\n",
    "}\n",
    "\n",
    "def enhanced_language_detection(text: str) -> str:\n",
    "    \"\"\"Enhanced language detection with fallbacks for Indian languages.\"\"\"\n",
    "    \n",
    "    # Simple script-based detection for better accuracy\n",
    "    def detect_by_script(text):\n",
    "        # Malayalam Unicode range\n",
    "        if re.search(r'[\\u0D00-\\u0D7F]', text):\n",
    "            return 'ml'\n",
    "        # Hindi/Devanagari Unicode range\n",
    "        elif re.search(r'[\\u0900-\\u097F]', text):\n",
    "            return 'hi'\n",
    "        # Tamil Unicode range\n",
    "        elif re.search(r'[\\u0B80-\\u0BFF]', text):\n",
    "            return 'ta'\n",
    "        # Telugu Unicode range\n",
    "        elif re.search(r'[\\u0C00-\\u0C7F]', text):\n",
    "            return 'te'\n",
    "        # Kannada Unicode range\n",
    "        elif re.search(r'[\\u0C80-\\u0CFF]', text):\n",
    "            return 'kn'\n",
    "        return None\n",
    "    \n",
    "    # Try script-based detection first\n",
    "    script_lang = detect_by_script(text)\n",
    "    if script_lang:\n",
    "        return script_lang\n",
    "    \n",
    "    # Fallback to langdetect\n",
    "    try:\n",
    "        detected = detect(text)\n",
    "        return detected if detected in SUPPORTED_LANGUAGES else 'en'\n",
    "    except:\n",
    "        return 'en'\n",
    "\n",
    "def translate_with_googletrans(text: str, target_lang: str, source_lang: str = 'en') -> str:\n",
    "    \"\"\"Translation using Google Translate.\"\"\"\n",
    "    \n",
    "    if source_lang == target_lang or not text.strip():\n",
    "        return text\n",
    "    \n",
    "    source_code = GOOGLE_LANG_CODES.get(source_lang, 'en')\n",
    "    target_code = GOOGLE_LANG_CODES.get(target_lang, 'en')\n",
    "    \n",
    "    try:\n",
    "        translator = Translator()\n",
    "        \n",
    "        # Add small delay to avoid rate limiting\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        print(f\"ğŸ”„ Translating from {LANGUAGE_MAPPINGS.get(source_lang, 'Unknown')} to {LANGUAGE_MAPPINGS.get(target_lang, 'Unknown')}...\")\n",
    "        print(f\"ğŸ“ Original text: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
    "        \n",
    "        result = translator.translate(text, src=source_code, dest=target_code)\n",
    "        translated = result.text\n",
    "        \n",
    "        print(f\"âœ… Translation result: {translated[:100]}{'...' if len(translated) > 100 else ''}\")\n",
    "        \n",
    "        if not translated or not translated.strip():\n",
    "            print(\"âš ï¸ Translation returned empty result, using original text\")\n",
    "            return text\n",
    "            \n",
    "        return translated\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Google Translate error: {e}\")\n",
    "        print(f\"ğŸ”„ Returning original text as fallback\")\n",
    "        return text\n",
    "\n",
    "def translate_with_gemini(text: str, target_lang: str, source_lang: str = 'en', llm=None) -> str:\n",
    "    \"\"\"Backup translation using Gemini (if Google Translate fails).\"\"\"\n",
    "    \n",
    "    if source_lang == target_lang or not text.strip():\n",
    "        return text\n",
    "    \n",
    "    if not llm:\n",
    "        print(\"âš ï¸ No LLM provided for Gemini translation\")\n",
    "        return text\n",
    "    \n",
    "    source_name = LANGUAGE_MAPPINGS.get(source_lang, 'English')\n",
    "    target_name = LANGUAGE_MAPPINGS.get(target_lang, 'English')\n",
    "    \n",
    "    translation_prompt = f\"\"\"You are a professional translator. Translate the following text accurately from {source_name} to {target_name}.\n",
    "\n",
    "Rules:\n",
    "1. Provide ONLY the translation, no explanations\n",
    "2. Maintain the original meaning and context\n",
    "3. Use natural, fluent {target_name}\n",
    "4. Do not add any prefixes, suffixes, or explanations\n",
    "\n",
    "Text to translate: {text}\n",
    "\n",
    "Translation:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ”„ Using Gemini for {source_name} to {target_name} translation...\")\n",
    "        \n",
    "        response = llm.invoke(translation_prompt)\n",
    "        translated = response.content.strip()\n",
    "        \n",
    "        print(f\"âœ… Gemini translation result: {translated[:100]}{'...' if len(translated) > 100 else ''}\")\n",
    "        \n",
    "        if not translated or not translated.strip():\n",
    "            print(\"âš ï¸ Gemini translation returned empty result\")\n",
    "            return text\n",
    "            \n",
    "        return translated\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Gemini translation error: {e}\")\n",
    "        return text\n",
    "\n",
    "def robust_translate(text: str, target_lang: str, source_lang: str = 'en', llm=None) -> str:\n",
    "    \"\"\"Try Google Translate first, fallback to Gemini if needed.\"\"\"\n",
    "    \n",
    "    if source_lang == target_lang or not text.strip():\n",
    "        return text\n",
    "    \n",
    "    # Try Google Translate first\n",
    "    result = translate_with_googletrans(text, target_lang, source_lang)\n",
    "    \n",
    "    # If Google Translate fails or returns unchanged text, try Gemini\n",
    "    if not result or not result.strip() or result == text:\n",
    "        print(\"ğŸ”„ Google Translate failed, trying Gemini as fallback...\")\n",
    "        if llm:\n",
    "            result = translate_with_gemini(text, target_lang, source_lang, llm)\n",
    "        else:\n",
    "            print(\"âš ï¸ No LLM available for Gemini fallback\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ===============================\n",
    "# Data Loading and Processing\n",
    "# ===============================\n",
    "\n",
    "def load_and_process_data(csv_path: str):\n",
    "    \"\"\"Load and preprocess the course data.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['Who This Course is For'] = df['Who This Course is For'].fillna(\"Not specified\")\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    # Language mapping\n",
    "    lang_map = {\n",
    "        6: \"Hindi\",\n",
    "        7: \"Kannada\", \n",
    "        11: \"Malayalam\",\n",
    "        20: \"Tamil\",\n",
    "        21: \"Telugu\",\n",
    "        24: \"English\"\n",
    "    }\n",
    "    \n",
    "    def map_languages(cell):\n",
    "        if pd.isna(cell):\n",
    "            return [\"English\"]\n",
    "        codes = str(cell).split(\",\")\n",
    "        return [lang_map.get(int(c.strip()), f\"Unknown-{c.strip()}\") for c in codes if c.strip().isdigit()]\n",
    "    \n",
    "    df['Released Languages'] = df['Released Languages'].apply(map_languages)\n",
    "    return df\n",
    "\n",
    "def create_documents_and_vectordb(df, persist_dir: str = \"data/chroma_db\"):\n",
    "    \"\"\"Create document chunks and build vector database.\"\"\"\n",
    "    documents = []\n",
    "    metadata_list = []\n",
    "    MAX_TOKENS = 200\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        description_chunks = wrap(str(row['Course Description']), MAX_TOKENS) or [\"\"]\n",
    "        \n",
    "        for desc_chunk in description_chunks:\n",
    "            text = f\"Course Title: {row['Course Title']}\\n\" \\\n",
    "                   f\"Description: {desc_chunk}\\n\" \\\n",
    "                   f\"Who This Course is For: {row['Who This Course is For']}\\n\" \\\n",
    "                   f\"Languages: {', '.join(row['Released Languages'])}\"\n",
    "            documents.append(text)\n",
    "            metadata_list.append({\n",
    "                \"course_no\": row['Course No'],\n",
    "                \"course_title\": row['Course Title'], \n",
    "                \"released_languages\": ', '.join(row['Released Languages']),\n",
    "                \"who_for\": row['Who This Course is For']\n",
    "            })\n",
    "    \n",
    "    # Create embeddings\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    vectordb = Chroma.from_texts(\n",
    "        texts=documents,\n",
    "        embedding=embedding_model,\n",
    "        metadatas=metadata_list,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "    \n",
    "    vectordb.persist()\n",
    "    return vectordb\n",
    "\n",
    "# ===============================\n",
    "# Setup LLM\n",
    "# ===============================\n",
    "\n",
    "def setup_gemini_llm():\n",
    "    \"\"\"Initialize Gemini LLM.\"\"\"\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "    \n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        google_api_key=api_key,\n",
    "        temperature=0.0,\n",
    "        max_tokens=512,\n",
    "        timeout=30,\n",
    "        max_retries=3\n",
    "    )\n",
    "\n",
    "# ===============================\n",
    "# Enhanced RAG Query Function\n",
    "# ===============================\n",
    "\n",
    "def enhanced_rag_query(user_query: str, vectordb, llm):\n",
    "    \"\"\"\n",
    "    Enhanced RAG query with Google Translate and Gemini fallback.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Processing query: {user_query[:50]}...\")\n",
    "    \n",
    "    # Step 1: Enhanced language detection\n",
    "    query_lang = enhanced_language_detection(user_query)\n",
    "    lang_name = LANGUAGE_MAPPINGS.get(query_lang, 'Unknown')\n",
    "    print(f\"ğŸŒ Detected language: {lang_name} ({query_lang})\")\n",
    "    \n",
    "    # Step 2: Translate to English for retrieval if needed\n",
    "    if query_lang != 'en':\n",
    "        print(\"ğŸ”„ Translating query to English...\")\n",
    "        english_query = robust_translate(user_query, 'en', query_lang, llm)\n",
    "        print(f\"ğŸ“ English query: {english_query}\")\n",
    "        \n",
    "        # Fallback if translation completely fails\n",
    "        if not english_query or english_query.strip() == \"\":\n",
    "            print(\"âš ï¸ Translation failed completely, using original query\")\n",
    "            english_query = user_query\n",
    "    else:\n",
    "        english_query = user_query\n",
    "    \n",
    "    # Step 3: Retrieve relevant documents\n",
    "    print(\"ğŸ” Searching for relevant courses...\")\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "    docs = retriever.get_relevant_documents(english_query)\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    print(f\"ğŸ“„ Retrieved context length: {len(context)} characters\")\n",
    "    \n",
    "    # Step 4: Generate response with improved prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant for Boswallah courses. Based on the provided course information, answer the user's question completely and accurately.\n",
    "\n",
    "Course Information Available:\n",
    "{context}\n",
    "\n",
    "User Question: {english_query}\n",
    "\n",
    "Instructions:\n",
    "- Provide a complete, detailed answer based on the course information\n",
    "- If the exact information isn't available, explain what related information is available\n",
    "- Be specific about course names, details, and requirements\n",
    "- Write a comprehensive response (at least 2-3 sentences)\n",
    "\n",
    "Complete Answer:\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¤– Generating response...\")\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        english_answer = response.content.strip()\n",
    "        print(f\"âœ… Generated English answer: {english_answer[:150]}{'...' if len(english_answer) > 150 else ''}\")\n",
    "        \n",
    "        # Check if English answer is empty\n",
    "        if not english_answer or not english_answer.strip():\n",
    "            print(\"âš ï¸ Generated answer is empty\")\n",
    "            english_answer = \"I couldn't find specific information about your question in the available course data. Please try rephrasing your question or contact support for more details.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating response: {e}\")\n",
    "        english_answer = \"I encountered an error while processing your question. Please try again or contact support.\"\n",
    "    \n",
    "    # Step 5: Translate response back to original language if needed\n",
    "    if query_lang != 'en':\n",
    "        print(f\"ğŸ”„ Translating response back to {lang_name}...\")\n",
    "        final_answer = robust_translate(english_answer, query_lang, 'en', llm)\n",
    "        \n",
    "        # Double-check final answer isn't empty\n",
    "        if not final_answer or not final_answer.strip():\n",
    "            print(\"âš ï¸ Final translation failed, providing English answer with note\")\n",
    "            final_answer = f\"[English response - translation unavailable]: {english_answer}\"\n",
    "            \n",
    "    else:\n",
    "        final_answer = english_answer\n",
    "    \n",
    "    return {\n",
    "        'query': user_query,\n",
    "        'detected_language': lang_name,\n",
    "        'english_query': english_query,\n",
    "        'english_answer': english_answer,\n",
    "        'answer': final_answer,\n",
    "        'retrieved_docs': len(docs)\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# Main Pipeline Class\n",
    "# ===============================\n",
    "\n",
    "class MultilingualRAGPipeline:\n",
    "    \"\"\"Complete multilingual RAG pipeline for Boswallah courses.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path: str, persist_dir: str = \"data/chroma_db\"):\n",
    "        self.csv_path = csv_path\n",
    "        self.persist_dir = persist_dir\n",
    "        self.vectordb = None\n",
    "        self.llm = None\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the pipeline.\"\"\"\n",
    "        print(\"ğŸš€ Initializing Multilingual RAG Pipeline...\")\n",
    "        \n",
    "        # Setup LLM\n",
    "        print(\"ğŸ”§ Setting up Gemini LLM...\")\n",
    "        self.llm = setup_gemini_llm()\n",
    "        \n",
    "        # Load and process data\n",
    "        print(\"ğŸ“ Loading course data...\")\n",
    "        df = load_and_process_data(self.csv_path)\n",
    "        print(f\"âœ… Loaded {len(df)} courses\")\n",
    "        \n",
    "        # Create vector database\n",
    "        print(\"ğŸ” Creating vector database...\")\n",
    "        self.vectordb = create_documents_and_vectordb(df, self.persist_dir)\n",
    "        print(\"âœ… Vector database created and persisted!\")\n",
    "        \n",
    "        print(\"ğŸ‰ Pipeline initialization complete!\")\n",
    "    \n",
    "    def query(self, user_query: str):\n",
    "        \"\"\"Process a user query.\"\"\"\n",
    "        if not self.vectordb or not self.llm:\n",
    "            raise ValueError(\"Pipeline not initialized. Call initialize() first.\")\n",
    "        \n",
    "        return enhanced_rag_query(user_query, self.vectordb, self.llm)\n",
    "\n",
    "# ===============================\n",
    "# Usage Example\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize pipeline\n",
    "    pipeline = MultilingualRAGPipeline(\"data/bw_courses - Sheet1.csv\")\n",
    "    pipeline.initialize()\n",
    "    \n",
    "    # Test queries in different languages\n",
    "    test_queries = [\n",
    "        \"Which courses are available in Tamil?\",\n",
    "        \"à´’à´°àµ à´¡àµ†à´¯àµâ€Œà´±à´¿ à´«à´¾à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´à´¤àµà´° à´ªà´¶àµà´•àµà´•àµ¾ à´†à´µà´¶àµà´¯à´®à´¾à´•àµà´‚?\",  # Malayalam\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"TEST {i}: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            result = pipeline.query(query)\n",
    "            print(f\"ğŸŒ Detected Language: {result['detected_language']}\")\n",
    "            print(f\"ğŸ“š Retrieved Documents: {result['retrieved_docs']}\")\n",
    "            print(f\"ğŸ” English Query: {result.get('english_query', 'N/A')}\")\n",
    "            print(f\"ğŸ”¤ English Answer: {result.get('english_answer', 'N/A')[:200]}{'...' if len(result.get('english_answer', '')) > 200 else ''}\")\n",
    "            print(f\"ğŸ¤– Final Answer: {result['answer']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        print()\n",
    "        time.sleep(1)  # Small delay between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbec60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bosswallah_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
